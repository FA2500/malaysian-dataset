{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed869c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocalsound_label = {'cough', 'laugh', 'sigh', 'sneeze', 'sniff', 'throatclearing'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c9d2632",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from bs4 import BeautifulSoup\n",
    "import soundfile as sf\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from multiprocess import Pool\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield (l[i: i + n], i // n)\n",
    "\n",
    "def multiprocessing(strings, function, cores=6, returned=True):\n",
    "    df_split = chunks(strings, len(strings) // cores)\n",
    "    pool = Pool(cores)\n",
    "    pooled = pool.map(function, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if returned:\n",
    "        return list(itertools.chain(*pooled))\n",
    "\n",
    "timestamps = [i * 0.02 for i in range(1500 + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3fe2435",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!rm -rf ami-array-chunk\n",
    "!mkdir ami-array-chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97077d29",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "groups = defaultdict(list)\n",
    "for f in glob('words/*.xml'):\n",
    "    i = os.path.split(f)[1].split('.')[0]\n",
    "    groups[i].append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7dfc2bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def loop(groups_name):\n",
    "    groups_name, _ = groups_name\n",
    "    \n",
    "    data = []\n",
    "    for g in tqdm(groups_name):\n",
    "        f_audio = os.path.join(g, 'audio/*Array*')\n",
    "        f_audio = glob(f_audio)\n",
    "        \n",
    "        if not len(f_audio):\n",
    "            continue\n",
    "            \n",
    "        ys = []\n",
    "        for f_audio_ in random.sample(f_audio, 1):\n",
    "            ys.append(sf.read(f_audio_))\n",
    "\n",
    "        all_segments = []\n",
    "        for f in groups[g]:\n",
    "            with open(f) as fopen:\n",
    "                d = fopen.read()\n",
    "            soup = BeautifulSoup(d, \"xml\")\n",
    "            elements = soup.find_all(['vocalsound', 'w'])\n",
    "            for element in elements:\n",
    "                try:\n",
    "                    all_segments.append({\n",
    "                        'element': element,\n",
    "                        'start': float(element.attrs['starttime']),\n",
    "                        'end': float(element.attrs['endtime']),\n",
    "                    })\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        all_segments = sorted(all_segments, key = lambda x: x['start'])\n",
    "        chunks, temp, = [], []\n",
    "        initial = 0\n",
    "        for element in all_segments:\n",
    "            element = element['element']\n",
    "            if initial == 0:\n",
    "                initial = float(element.attrs['starttime'])\n",
    "                temp.append(element)\n",
    "            else:\n",
    "                l = (float(element.attrs['endtime']) - initial)\n",
    "                if l > 30:\n",
    "                    chunks.append(temp)\n",
    "                    initial = float(element.attrs['starttime'])\n",
    "                    temp = [element]\n",
    "                else:\n",
    "                    temp.append(element)\n",
    "\n",
    "        if len(temp):\n",
    "            chunks.append(temp)\n",
    "\n",
    "        for no, chunk in enumerate(chunks):\n",
    "            start = float(chunk[0].attrs['starttime'])\n",
    "            end = float(chunk[-1].attrs['starttime'])\n",
    "            segments = []\n",
    "            for c in chunk:\n",
    "                start_time = float(c.attrs.get('starttime')) - start\n",
    "                end_time = float(c.attrs.get('endtime')) - start\n",
    "                text = c.get_text()\n",
    "                if c.name == 'vocalsound':\n",
    "                    if 'other' in c.attrs['type']:\n",
    "                        continue\n",
    "                    else:\n",
    "                        t = c.attrs['type']\n",
    "                        segments.append({\n",
    "                            'text': f'<|{t}|>',\n",
    "                            'start': start_time,\n",
    "                            'end': end_time,\n",
    "                        })\n",
    "                if c.name == 'w':\n",
    "                    if 'punc' in c.attrs:\n",
    "                        try:\n",
    "                            segments[-1]['text'] += text\n",
    "                            segments[-1]['end'] = end_time\n",
    "                        except:\n",
    "                            pass\n",
    "                    else:\n",
    "                        segments.append({\n",
    "                            'text': text,\n",
    "                            'start': start_time,\n",
    "                            'end': end_time,\n",
    "                        })\n",
    "\n",
    "            for n in range(len(ys)):\n",
    "                y_, sr_ = ys[n]\n",
    "                y__ = y_[int(start * sr_): int(end * sr_)]\n",
    "                new_f = os.path.join('ami-array-chunk', f'{g}-{no}-{n}.mp3')\n",
    "                sf.write(new_f, y__, 16000)\n",
    "                data.append({\n",
    "                    'audio_filename': new_f,\n",
    "                    'segments': segments,\n",
    "                })\n",
    "                \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be680963",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_name = list(groups.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449a712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                     | 0/1 [00:07<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "data = loop((groups_name[:1], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cffc7759",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:08<00:00,  7.54s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:08<00:00,  7.55s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:11<00:00,  7.75s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.96s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:21<00:00,  8.33s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:22<00:00,  8.37s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:23<00:00,  8.45s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:27<00:00,  8.67s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:28<00:00,  8.76s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:30<00:00,  8.83s/it]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:33<00:00,  9.02s/it]\n"
     ]
    }
   ],
   "source": [
    "data = multiprocessing(groups_name, loop, cores = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "548ffe9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11555"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c78a74ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('ami.json', 'w') as fopen:\n",
    "    json.dump(data, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06921449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "34d25e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted = []\n",
    "for d in data:\n",
    "    align = d['segments']\n",
    "    if not len(align):\n",
    "        continue\n",
    "    segments, temp = [], [align[0]]\n",
    "    last_t = align[0]['end']\n",
    "    for c in align[1:]:\n",
    "        if (c['start'] - last_t) > 0.25:\n",
    "            segments.append(temp)\n",
    "            temp = []\n",
    "\n",
    "        last_t = c['end']\n",
    "        temp.append(c)\n",
    "\n",
    "    if len(temp):\n",
    "        segments.append(temp)\n",
    "        \n",
    "    ts = []\n",
    "    for s in segments:\n",
    "        start = min(timestamps, key=lambda t: abs(t - s[0]['start']))\n",
    "        end = min(timestamps, key=lambda t: abs(t - s[-1]['end']))\n",
    "        w = ' '.join([c['text'] for c in s])\n",
    "        w = unidecode(w)\n",
    "        t = f\"<|{start:.2f}|> {w}<|{end:.2f}|>\"\n",
    "        ts.append(t)\n",
    "\n",
    "    ts = ''.join(ts)\n",
    "    new_text = text = f\"<|startoftranscript|><|en|><|transcribenonverbal|>{ts}<|endoftext|>\"\n",
    "    formatted.append({\n",
    "        'audio_filename': d['audio_filename'],\n",
    "        'new_text': new_text,\n",
    "        'source': 'AMI'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5309b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(formatted).to_parquet('ami.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78678c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a8179e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/Speech-Nonverbal-Whisper/commit/295f3445439fd408771185dc2e63c2c851a28ba4', commit_message='Upload data/ami-00000-of-00001.parquet with huggingface_hub', commit_description='', oid='295f3445439fd408771185dc2e63c2c851a28ba4', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/mesolitica/Speech-Nonverbal-Whisper', endpoint='https://huggingface.co', repo_type='dataset', repo_id='mesolitica/Speech-Nonverbal-Whisper'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj=\"ami.parquet\",\n",
    "    path_in_repo=\"data/ami-00000-of-00001.parquet\",\n",
    "    repo_id=\"mesolitica/Speech-Nonverbal-Whisper\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24b3f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -rq ami-array-chunk.zip ami-array-chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe26f2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97cb2d9475d5438e97c41c70ddaf842e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ami-array-chunk.zip:   0%|          | 0.00/1.47G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/mesolitica/Speech-Nonverbal-Whisper/commit/1ffceb86209606c7b7a7641ad2bb392398581e56', commit_message='Upload ami-array-chunk.zip with huggingface_hub', commit_description='', oid='1ffceb86209606c7b7a7641ad2bb392398581e56', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/mesolitica/Speech-Nonverbal-Whisper', endpoint='https://huggingface.co', repo_type='dataset', repo_id='mesolitica/Speech-Nonverbal-Whisper'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj=\"ami-array-chunk.zip\",\n",
    "    path_in_repo=\"ami-array-chunk.zip\",\n",
    "    repo_id=\"mesolitica/Speech-Nonverbal-Whisper\",\n",
    "    repo_type=\"dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d0002",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
